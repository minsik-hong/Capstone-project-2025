import os
from dotenv import load_dotenv
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.chat_models import ChatOpenAI
from langchain_weaviate.vectorstores import WeaviateVectorStore
from langchain_huggingface import HuggingFaceEmbeddings
from weaviate import WeaviateClient
from weaviate.connect import ConnectionParams

load_dotenv()

# LLM ì„¤ì • (OpenAI API Key í•„ìš”)
llm = ChatOpenAI(
    model_name="gpt-3.5-turbo",  # ë˜ëŠ” "gpt-4"
    temperature=0,
)

# Weaviate ì—°ê²°
connection_params = ConnectionParams.from_params(
    http_host="localhost",
    http_port=8080,
    http_secure=False,
    grpc_host="localhost",
    grpc_port=50051,
    grpc_secure=False
)
client = WeaviateClient(connection_params=connection_params)
client.connect()

# VectorStore ë¶ˆëŸ¬ì˜¤ê¸° (ë‰´ìŠ¤ ì†ŒìŠ¤ëª…ì— ë”°ë¼ ë°”ê¿”ì£¼ì„¸ìš”)
embedding_model = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
vectorstore = WeaviateVectorStore(
    client=client,
    embedding=embedding_model,
    index_name="news_bbc",  # ë˜ëŠ” news_cnn
    text_key="text"
)

# ëŒ€í™” ë©”ëª¨ë¦¬ & QA ì²´ì¸ ìƒì„±
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True,
    output_key="answer" 
)
qa_chain = ConversationalRetrievalChain.from_llm(
    llm=llm,
    retriever=vectorstore.as_retriever(search_kwargs={"k": 5}),
    memory=memory,
    return_source_documents=True,
    output_key="answer"
)

# ëŒ€í™” ë£¨í”„ ì‹œì‘
def chat():
    print("ğŸ—ï¸ ë‰´ìŠ¤ ê¸°ë°˜ RAG ì±—ë´‡ì— ì˜¤ì‹  ê±¸ í™˜ì˜í•©ë‹ˆë‹¤!")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'exit'ì„ ì…ë ¥í•˜ì„¸ìš”.\n")
    while True:
        question = input("ğŸ‘¤ ì§ˆë¬¸: ")
        if question.lower() in ("exit", "quit"):
            print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        response = qa_chain.invoke({"question": question})
        answer = response["answer"]
        sources = [
            doc.metadata.get("url", "ì¶œì²˜ ì—†ìŒ")
            for doc in response.get("source_documents", [])
        ]
        print(f"\nğŸ¤– ë‹µë³€: {answer}")
        print("ğŸ”— ì¶œì²˜:")
        for src in sources:
            print(f" - {src}")
        print("\n" + "-" * 50 + "\n")

if __name__ == "__main__":
    chat()
    client.close()